{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f15f9d3b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-13T05:48:45.291544Z",
     "iopub.status.busy": "2024-08-13T05:48:45.291133Z",
     "iopub.status.idle": "2024-08-13T05:49:02.154870Z",
     "shell.execute_reply": "2024-08-13T05:49:02.153764Z"
    },
    "papermill": {
     "duration": 16.875345,
     "end_time": "2024-08-13T05:49:02.157551",
     "exception": false,
     "start_time": "2024-08-13T05:48:45.282206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 05:48:48.906001: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-13 05:48:48.906178: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-13 05:48:49.064051: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "from tensorflow.keras.initializers import GlorotUniform, HeNormal\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97489bbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.173590Z",
     "iopub.status.busy": "2024-08-13T05:49:02.172928Z",
     "iopub.status.idle": "2024-08-13T05:49:02.177939Z",
     "shell.execute_reply": "2024-08-13T05:49:02.176796Z"
    },
    "papermill": {
     "duration": 0.015326,
     "end_time": "2024-08-13T05:49:02.180131",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.164805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use this cell to empty the output folder\n",
    "# !rm -rf /kaggle/working/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "492b3547",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.195914Z",
     "iopub.status.busy": "2024-08-13T05:49:02.195222Z",
     "iopub.status.idle": "2024-08-13T05:49:02.342303Z",
     "shell.execute_reply": "2024-08-13T05:49:02.341035Z"
    },
    "papermill": {
     "duration": 0.157915,
     "end_time": "2024-08-13T05:49:02.345063",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.187148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_path = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\n",
    "train_csv_path = os.path.join(root_path, 'train.csv')\n",
    "train_csv = pd.read_csv(train_csv_path)\n",
    "coordinates_path = os.path.join(root_path, 'train_label_coordinates.csv')\n",
    "df_coor = pd.read_csv(coordinates_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dc77264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.360670Z",
     "iopub.status.busy": "2024-08-13T05:49:02.360232Z",
     "iopub.status.idle": "2024-08-13T05:49:02.366470Z",
     "shell.execute_reply": "2024-08-13T05:49:02.365315Z"
    },
    "papermill": {
     "duration": 0.016823,
     "end_time": "2024-08-13T05:49:02.368904",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.352081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read MRI volume\n",
    "# INPUT: A folder consisting of MRI slices\n",
    "# for example: /kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images/100206310/1012284084\"\n",
    "# OUTPUT: Image \n",
    "def readMRIVolume(mri_volume_path):\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    dicom_files = reader.GetGDCMSeriesFileNames(mri_volume_path)\n",
    "    reader.SetFileNames(dicom_files)\n",
    "    retrieved_mri_volume = reader.Execute()\n",
    "    return retrieved_mri_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "532a35d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.384618Z",
     "iopub.status.busy": "2024-08-13T05:49:02.384174Z",
     "iopub.status.idle": "2024-08-13T05:49:02.392057Z",
     "shell.execute_reply": "2024-08-13T05:49:02.390971Z"
    },
    "papermill": {
     "duration": 0.018299,
     "end_time": "2024-08-13T05:49:02.394264",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.375965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resample images to uniform voxel spacing\n",
    "# INPUT: Image\n",
    "# OUTPUT: Image\n",
    "def resample_image(input_volume, out_spacing=[1, 1, 1]):\n",
    "  \n",
    "    original_spacing = input_volume.GetSpacing()\n",
    "    original_size = input_volume.GetSize()\n",
    "\n",
    "    out_size = [\n",
    "        int(np.round(original_size[0] * (original_spacing[0] / out_spacing[0]))),\n",
    "        int(np.round(original_size[1] * (original_spacing[1] / out_spacing[1]))),\n",
    "        int(np.round(original_size[2] * (original_spacing[2] / out_spacing[2])))]\n",
    "\n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    resample.SetOutputSpacing(out_spacing)\n",
    "    resample.SetSize(out_size)\n",
    "    resample.SetOutputDirection(input_volume.GetDirection())\n",
    "    resample.SetOutputOrigin(input_volume.GetOrigin())\n",
    "    resample.SetTransform(sitk.Transform())\n",
    "    resample.SetDefaultPixelValue(input_volume.GetPixelIDValue())\n",
    "\n",
    "    return resample.Execute(input_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62e2eba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.409825Z",
     "iopub.status.busy": "2024-08-13T05:49:02.409437Z",
     "iopub.status.idle": "2024-08-13T05:49:02.416132Z",
     "shell.execute_reply": "2024-08-13T05:49:02.415023Z"
    },
    "papermill": {
     "duration": 0.017215,
     "end_time": "2024-08-13T05:49:02.418509",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.401294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resize images to fixed spatial resolution in pixels\n",
    "# INPUT: Image\n",
    "# OUTPUT: Image\n",
    "def resize_image(input_volume, output_size=320):\n",
    "    num_axial_slices = int(input_volume.GetSize()[-1])\n",
    "    output_size = [output_size, output_size, num_axial_slices]\n",
    "    scale = np.divide(input_volume.GetSize(), output_size)\n",
    "    spacing = np.multiply(input_volume.GetSpacing(), scale)\n",
    "    transform = sitk.AffineTransform(3)\n",
    "    resized_volume = sitk.Resample(input_volume, output_size, transform, sitk.sitkLinear, input_volume.GetOrigin(),\n",
    "                                  spacing, \n",
    "    input_volume.GetDirection())\n",
    "    return resized_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f605bfc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.433891Z",
     "iopub.status.busy": "2024-08-13T05:49:02.433504Z",
     "iopub.status.idle": "2024-08-13T05:49:02.438493Z",
     "shell.execute_reply": "2024-08-13T05:49:02.437427Z"
    },
    "papermill": {
     "duration": 0.015462,
     "end_time": "2024-08-13T05:49:02.440963",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.425501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INPUT: Image\n",
    "# OUTPUT: Numpy array\n",
    "def extract_slices(image_volume):\n",
    "    image_array = sitk.GetArrayFromImage(image_volume)\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "335b043f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.456417Z",
     "iopub.status.busy": "2024-08-13T05:49:02.456009Z",
     "iopub.status.idle": "2024-08-13T05:49:02.462212Z",
     "shell.execute_reply": "2024-08-13T05:49:02.461164Z"
    },
    "papermill": {
     "duration": 0.016575,
     "end_time": "2024-08-13T05:49:02.464503",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.447928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dicom_stack(dicom_folder_path):\n",
    "    try:\n",
    "        mri_image_vol = readMRIVolume(dicom_folder_path) # this is excpected to throw exception\n",
    "        resampled_img = resample_image(mri_image_vol)\n",
    "        resized_img = resize_image(resampled_img) \n",
    "        img_numpy_arr =  extract_slices(resized_img) # someNumber * 320 * 320\n",
    "        img_middle_slice = img_numpy_arr[len(img_numpy_arr) // 2] # 320 * 320\n",
    "        return img_middle_slice\n",
    "    except Exception as e:\n",
    "        print(f\"An exception occured occurred: {e}\")\n",
    "        return np.zeros((320, 320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cefc92d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.480664Z",
     "iopub.status.busy": "2024-08-13T05:49:02.480268Z",
     "iopub.status.idle": "2024-08-13T05:49:02.489909Z",
     "shell.execute_reply": "2024-08-13T05:49:02.488774Z"
    },
    "papermill": {
     "duration": 0.020465,
     "end_time": "2024-08-13T05:49:02.492494",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.472029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INPUTS: \n",
    "#    meta_df (Pandas dataframe): metadata of Images\n",
    "#.   image_path (String): The path to Images\n",
    "#    OUTPUT: A Numpy array of size (data_points * 3 * 320 * 320)\n",
    "\n",
    "# TRAINING: \n",
    "#   meta_df = train_meta_df\n",
    "#   image_path = train_images_path\n",
    "\n",
    "# NOTE: not using tqdm because print() and tqdm.write() is causing problems\n",
    "def create_dataset(meta_df, image_path, data_points_input=None):\n",
    "    count_df = meta_df.groupby('study_id').size().reset_index(name='count')\n",
    "    \n",
    "    if data_points_input is not None:\n",
    "        count_df = count_df.head(data_points_input)\n",
    "        \n",
    "    data_points = count_df.shape[0]\n",
    "    data_set = np.empty((data_points, 3, 320, 320)) \n",
    "    \n",
    "    for i in range(data_points):\n",
    "        print(f\"{i+1}th iteration out of {data_points}\")\n",
    "        study_ID = count_df.study_id.iloc[i]\n",
    "        study = meta_df.loc[meta_df.study_id == study_ID]\n",
    "\n",
    "        for row in study.itertuples():\n",
    "            path = os.path.join(image_path, str(row.study_id), str(row.series_id))\n",
    "\n",
    "            if row.series_description == \"Sagittal T2/STIR\":\n",
    "                sag_t2_mid_slice = load_dicom_stack(path) # 320 * 320\n",
    "            elif row.series_description == \"Sagittal T1\":\n",
    "                sag_t1_mid_slice = load_dicom_stack(path) # 320 * 320\n",
    "            elif row.series_description == \"Axial T2\":\n",
    "                ax_t2_mid_slice = load_dicom_stack(path) # 320 * 320\n",
    "\n",
    "        curr_set = np.stack((sag_t2_mid_slice, sag_t1_mid_slice, ax_t2_mid_slice), axis=0) # (3*320*320)\n",
    "        data_set[i] = curr_set \n",
    "            \n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd6ddad4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.508661Z",
     "iopub.status.busy": "2024-08-13T05:49:02.507545Z",
     "iopub.status.idle": "2024-08-13T05:49:02.540014Z",
     "shell.execute_reply": "2024-08-13T05:49:02.538931Z"
    },
    "papermill": {
     "duration": 0.043269,
     "end_time": "2024-08-13T05:49:02.542697",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.499428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_description_path = os.path.join(root_path, 'train_series_descriptions.csv')\n",
    "train_meta_df = pd.read_csv(train_description_path)\n",
    "train_meta_df = train_meta_df.drop_duplicates(subset=['study_id', 'series_description'])\n",
    "train_images_path = os.path.join(root_path, 'train_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "758af309",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.558494Z",
     "iopub.status.busy": "2024-08-13T05:49:02.558093Z",
     "iopub.status.idle": "2024-08-13T05:49:02.563390Z",
     "shell.execute_reply": "2024-08-13T05:49:02.562331Z"
    },
    "papermill": {
     "duration": 0.015966,
     "end_time": "2024-08-13T05:49:02.565713",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.549747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load(path):\n",
    "    shape = (1975, 320, 320, 3)\n",
    "    data_set = np.memmap(path, mode='r', shape=shape)\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b0eb6a",
   "metadata": {
    "papermill": {
     "duration": 0.006534,
     "end_time": "2024-08-13T05:49:02.579088",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.572554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "[[3 3 4 ... 0 0 0]\n",
    " [3 5 7 ... 0 0 0]\n",
    " [3 5 9 ... 0 0 0]\n",
    " ...\n",
    " [1 3 4 ... 0 0 0]\n",
    " [1 3 4 ... 0 0 0]\n",
    " [1 1 1 ... 0 0 0]]\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5158b989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.594443Z",
     "iopub.status.busy": "2024-08-13T05:49:02.594028Z",
     "iopub.status.idle": "2024-08-13T05:49:02.601158Z",
     "shell.execute_reply": "2024-08-13T05:49:02.599843Z"
    },
    "papermill": {
     "duration": 0.017497,
     "end_time": "2024-08-13T05:49:02.603427",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.585930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_labels():\n",
    "    train_csv_copy = train_csv.copy()\n",
    "\n",
    "    new_columns = []\n",
    "    severities = ['Normal/Mild', 'Moderate', 'Severe']\n",
    "\n",
    "    for disease in train_csv_copy.columns[1:]:\n",
    "        for severity in severities:\n",
    "            new_col_name = f\"{disease}_{severity}\"\n",
    "            new_columns.append(new_col_name)\n",
    "            train_csv_copy[new_col_name] = 0\n",
    "            train_csv_copy.loc[train_csv_copy[disease] == severity, new_col_name] = 1\n",
    "\n",
    "    train_csv_copy = train_csv_copy.drop(columns=train_csv_copy.columns[0:26])\n",
    "    # print(train_csv_copy[0])\n",
    "    train_csv_copy = train_csv_copy.to_numpy()\n",
    "    # print(train_csv_copy)\n",
    "    \n",
    "    return train_csv_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "577e51a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.619048Z",
     "iopub.status.busy": "2024-08-13T05:49:02.618658Z",
     "iopub.status.idle": "2024-08-13T05:49:02.626295Z",
     "shell.execute_reply": "2024-08-13T05:49:02.625030Z"
    },
    "papermill": {
     "duration": 0.018302,
     "end_time": "2024-08-13T05:49:02.628640",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.610338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INPUT: numpy datasets \n",
    "# OUTPUT: tf datasets train_set, val_set\n",
    "# !!! num_samples=1975\n",
    "def create_tf_dataset(data_set, labels, num_samples=1975, train_ratio=0.8, batch_size=32, seed=42):\n",
    "    data_set_tf = tf.data.Dataset.from_tensor_slices(data_set)\n",
    "    labels_tf = tf.data.Dataset.from_tensor_slices(labels)\n",
    "\n",
    "    # Combine the inputs and labels\n",
    "    combined_set = tf.data.Dataset.zip((data_set_tf, labels_tf))\n",
    "    \n",
    "    # Shuffle and split the dataset\n",
    "    # Lets skip shuffling for now\n",
    "    # combined_set = combined_set.shuffle(buffer_size=num_samples, seed=seed)\n",
    "    train_size = int(num_samples * train_ratio)\n",
    "    train_set = combined_set.take(train_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    val_set = combined_set.skip(train_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return train_set, val_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fcdf92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-16T04:10:29.492672Z",
     "iopub.status.busy": "2024-07-16T04:10:29.492316Z",
     "iopub.status.idle": "2024-07-16T04:10:29.498052Z",
     "shell.execute_reply": "2024-07-16T04:10:29.497074Z",
     "shell.execute_reply.started": "2024-07-16T04:10:29.492647Z"
    },
    "papermill": {
     "duration": 0.006525,
     "end_time": "2024-08-13T05:49:02.642129",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.635604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b3ef98b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.657214Z",
     "iopub.status.busy": "2024-08-13T05:49:02.656826Z",
     "iopub.status.idle": "2024-08-13T05:49:02.664776Z",
     "shell.execute_reply": "2024-08-13T05:49:02.663581Z"
    },
    "papermill": {
     "duration": 0.01827,
     "end_time": "2024-08-13T05:49:02.667146",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.648876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    print(\"Creating the model....\")\n",
    "    model_input = tf.keras.Input(shape=input_shape, name='input')\n",
    "\n",
    "    base_model = EfficientNetV2B0(\n",
    "        include_top = False,\n",
    "        weights = '/kaggle/input/rsna-dataset-numpy-complete/efficientnetv2-b0_notop.h5', \n",
    "        input_shape = input_shape\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    base_model_features = base_model(model_input, training=False)\n",
    "    base_model_features = layers.GlobalAveragePooling2D()(base_model_features)\n",
    "    # base_model_features = layers.Dropout(0.2)(base_model_features) \n",
    "    \n",
    "    output = keras.layers.Dense(75, activation='softmax', kernel_initializer=GlorotUniform(), name='output')(base_model_features)\n",
    "    \n",
    "    model = Model(inputs=[model_input], outputs=[output])\n",
    "    \n",
    "    num_layers = len(base_model.layers)\n",
    "    # print(f\"Number of layers in the base model: {num_layers}\")\n",
    "\n",
    "    return model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fbf11c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.682780Z",
     "iopub.status.busy": "2024-08-13T05:49:02.682348Z",
     "iopub.status.idle": "2024-08-13T05:49:02.690203Z",
     "shell.execute_reply": "2024-08-13T05:49:02.688995Z"
    },
    "papermill": {
     "duration": 0.018672,
     "end_time": "2024-08-13T05:49:02.692782",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.674110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def train_test_save_model(train_dataset, validation_data, epochs_to_train):\n",
    "    \n",
    "    input_shape = (320, 320, 3)\n",
    "    model, base_model = create_model(input_shape)\n",
    "    print(model.summary(show_trainable=True))\n",
    "    \n",
    "    print(\"Compiling the model....\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(), \n",
    "        loss=keras.losses.BinaryCrossentropy(), \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"Training the model....\")\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=validation_data,\n",
    "        epochs=epochs_to_train,  # Number of epochs to train\n",
    "        verbose=1  # Verbosity mode\n",
    "    )\n",
    "\n",
    "    print(\"Evaluating the model....\")\n",
    "    results = model.evaluate(validation_data)\n",
    "    print(f\"Validation results - {results}\")\n",
    "\n",
    "    print(\"Saving the model....\")\n",
    "    model.save('non_fine_tuned_model.h5')\n",
    "    \n",
    "    return model, base_model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e38c0e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.708302Z",
     "iopub.status.busy": "2024-08-13T05:49:02.707905Z",
     "iopub.status.idle": "2024-08-13T05:49:02.715891Z",
     "shell.execute_reply": "2024-08-13T05:49:02.714752Z"
    },
    "papermill": {
     "duration": 0.018413,
     "end_time": "2024-08-13T05:49:02.718209",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.699796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fine tune the model\n",
    "# there are 270 layers in efficientNet_v2_b0\n",
    "def train_test_save_fine_tune_model(train_dataset, validation_data, epochs_to_train, epochs_to_fine_tune,layers_to_unfreeze):\n",
    "    model, base_model = train_test_save_model(train_dataset, validation_data, epochs_to_train)\n",
    "    \n",
    "    print(\"Starting the fine tuning process....\")\n",
    "    \n",
    "    for layer in base_model.layers[-layers_to_unfreeze:]:\n",
    "        layer.trainable = True\n",
    "    # base_model.trainable = True \n",
    "    \n",
    "    model.summary(show_trainable=True)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    print(\"Fitting the end-to-end model\")\n",
    "    model.fit(train_dataset, epochs=epochs_to_fine_tune, validation_data=validation_data)\n",
    "    \n",
    "    print(\"Evaluating the model....\")\n",
    "    results = model.evaluate(validation_data)\n",
    "    print(f\"Validation results - {results}\")\n",
    "    \n",
    "    print(\"Saving the model....\")\n",
    "    model.save('fine_tuned_model_one_layer_unfrozen.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a7f657",
   "metadata": {
    "papermill": {
     "duration": 0.006591,
     "end_time": "2024-08-13T05:49:02.731830",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.725239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "466cb276",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.746921Z",
     "iopub.status.busy": "2024-08-13T05:49:02.746499Z",
     "iopub.status.idle": "2024-08-13T05:49:02.757609Z",
     "shell.execute_reply": "2024-08-13T05:49:02.756527Z"
    },
    "papermill": {
     "duration": 0.021787,
     "end_time": "2024-08-13T05:49:02.760344",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.738557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to all the files\n",
    "test_images_path = os.path.join(root_path, 'test_images')\n",
    "test_description_path = os.path.join(root_path, 'test_series_descriptions.csv')\n",
    "test_meta_df = pd.read_csv(test_description_path)\n",
    "test_meta_df = test_meta_df.drop_duplicates(subset=['study_id', 'series_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78be6d3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.776357Z",
     "iopub.status.busy": "2024-08-13T05:49:02.775292Z",
     "iopub.status.idle": "2024-08-13T05:49:02.781465Z",
     "shell.execute_reply": "2024-08-13T05:49:02.780427Z"
    },
    "papermill": {
     "duration": 0.016364,
     "end_time": "2024-08-13T05:49:02.783751",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.767387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "    test_data_set = create_dataset(test_meta_df, test_images_path)\n",
    "    test_data_set = np.transpose(test_data_set, (0, 2, 3, 1))\n",
    "    test_tf = tf.data.Dataset.from_tensor_slices(test_data_set)\n",
    "    test_tf = test_tf.batch(32)\n",
    "    predictions = model.predict(test_tf)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b57c7a",
   "metadata": {
    "papermill": {
     "duration": 0.00651,
     "end_time": "2024-08-13T05:49:02.797021",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.790511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creation of the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e81dd0ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.813553Z",
     "iopub.status.busy": "2024-08-13T05:49:02.812435Z",
     "iopub.status.idle": "2024-08-13T05:49:02.822187Z",
     "shell.execute_reply": "2024-08-13T05:49:02.821087Z"
    },
    "papermill": {
     "duration": 0.020812,
     "end_time": "2024-08-13T05:49:02.824676",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.803864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_submission(predictions):\n",
    "    # Create the severity level columns\n",
    "    normal_mild_col = []\n",
    "    moderate_col = []\n",
    "    severe_col = []\n",
    "\n",
    "    for curr_75_element_array in predictions:\n",
    "        arrays = [normal_mild_col, moderate_col, severe_col]\n",
    "        for i, element in enumerate(curr_75_element_array):\n",
    "            arrays[i % 3].append(element) \n",
    "\n",
    "    normal_mild_col = np.array(normal_mild_col).flatten()\n",
    "    moderate_col = np.array(moderate_col).flatten()\n",
    "    severe_col = np.array(severe_col).flatten()\n",
    "    \n",
    "    # Create the row id column\n",
    "    row_id_col = []\n",
    "    test_meta_df_copy = test_meta_df.copy()\n",
    "    unique_study_ids = test_meta_df_copy[['study_id']].drop_duplicates().reset_index(drop=True)\n",
    "    diseases_array = train_csv.copy().columns[1:].to_numpy()\n",
    "    for study_id in unique_study_ids['study_id']:\n",
    "        for disease in diseases_array:\n",
    "            # row_id_col.append({'row_id': f'{study_id}_{disease}'})\n",
    "            row_id_col.append(f'{study_id}_{disease}')\n",
    "\n",
    "    data = {\n",
    "        'row_id': row_id_col,\n",
    "        'normal_mild': normal_mild_col,\n",
    "        'moderate': moderate_col,\n",
    "        'severe': severe_col\n",
    "    }\n",
    "    submission_df = pd.DataFrame(data)\n",
    "    submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4458933d",
   "metadata": {
    "papermill": {
     "duration": 0.00649,
     "end_time": "2024-08-13T05:49:02.838106",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.831616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### The following cell contains the data creation code, which runs only once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07684a88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.853761Z",
     "iopub.status.busy": "2024-08-13T05:49:02.853317Z",
     "iopub.status.idle": "2024-08-13T05:49:02.859273Z",
     "shell.execute_reply": "2024-08-13T05:49:02.858151Z"
    },
    "papermill": {
     "duration": 0.016503,
     "end_time": "2024-08-13T05:49:02.861596",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.845093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def np_dataset_creation():\n",
    "    data_set = create_dataset(train_meta_df, train_images_path) # 5922 * 3 * 320 * 320\n",
    "    data_set = np.transpose(data_set, (0, 2, 3, 1))  # 5922 * 320 * 320 * 3\n",
    "    print(f\"shape: {data_set.shape}\")\n",
    "    np.save('numpy_4d_npy_array', data_set)\n",
    "    \n",
    "# np_dataset_creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ef0e47f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.876931Z",
     "iopub.status.busy": "2024-08-13T05:49:02.876555Z",
     "iopub.status.idle": "2024-08-13T05:49:02.881844Z",
     "shell.execute_reply": "2024-08-13T05:49:02.880752Z"
    },
    "papermill": {
     "duration": 0.015677,
     "end_time": "2024-08-13T05:49:02.884179",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.868502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data_set():\n",
    "    data_set_path = '/kaggle/input/rsna-dataset-numpy-complete/numpy_4d_npy_array.npy'\n",
    "    data_set = load(data_set_path)\n",
    "    print(data_set.shape)\n",
    "    return data_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73741baf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T05:49:02.901262Z",
     "iopub.status.busy": "2024-08-13T05:49:02.900867Z",
     "iopub.status.idle": "2024-08-13T06:11:05.298432Z",
     "shell.execute_reply": "2024-08-13T06:11:05.297110Z"
    },
    "papermill": {
     "duration": 1322.409317,
     "end_time": "2024-08-13T06:11:05.301309",
     "exception": false,
     "start_time": "2024-08-13T05:49:02.891992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1975, 320, 320, 3)\n",
      "Creating the model....\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                </span>┃<span style=\"font-weight: bold\"> Output Shape          </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Trai… </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ efficientnetv2-b0           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,919,312</span> │   <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">N</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ global_average_pooling2d    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)    │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">96,075</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n",
       "└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTrai…\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ input (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m3\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ efficientnetv2-b0           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1280\u001b[0m)  │  \u001b[38;5;34m5,919,312\u001b[0m │   \u001b[1;91mN\u001b[0m   │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ global_average_pooling2d    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)    │                       │            │       │\n",
       "├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m)            │     \u001b[38;5;34m96,075\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n",
       "└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,015,387</span> (22.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,015,387\u001b[0m (22.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96,075</span> (375.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m96,075\u001b[0m (375.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,919,312</span> (22.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,919,312\u001b[0m (22.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Compiling the model....\n",
      "Training the model....\n",
      "Epoch 1/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 2s/step - accuracy: 0.0314 - loss: 0.4620 - val_accuracy: 0.0127 - val_loss: 0.3629\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 2s/step - accuracy: 0.0617 - loss: 0.3732 - val_accuracy: 0.1544 - val_loss: 0.3618\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 0.1566 - loss: 0.3713 - val_accuracy: 0.2937 - val_loss: 0.3619\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - accuracy: 0.1972 - loss: 0.3717 - val_accuracy: 0.7089 - val_loss: 0.3620\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 2s/step - accuracy: 0.2459 - loss: 0.3709 - val_accuracy: 0.7013 - val_loss: 0.3620\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - accuracy: 0.2708 - loss: 0.3709 - val_accuracy: 0.6481 - val_loss: 0.3619\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - accuracy: 0.2967 - loss: 0.3707 - val_accuracy: 0.8000 - val_loss: 0.3618\n",
      "Epoch 8/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - accuracy: 0.3044 - loss: 0.3708 - val_accuracy: 0.8532 - val_loss: 0.3623\n",
      "Epoch 9/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - accuracy: 0.3466 - loss: 0.3703 - val_accuracy: 0.8304 - val_loss: 0.3623\n",
      "Epoch 10/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2s/step - accuracy: 0.3148 - loss: 0.3698 - val_accuracy: 0.8228 - val_loss: 0.3622\n",
      "Evaluating the model....\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.8043 - loss: 0.3684\n",
      "Validation results - [0.3622101843357086, 0.8227847814559937]\n",
      "Saving the model....\n"
     ]
    }
   ],
   "source": [
    "def complete_training_workflow(data_set, epochs_to_train, epochs_to_fine_tune, layers_to_unfreeze):\n",
    "    labels = create_labels()\n",
    "    train_dataset, validation_data = create_tf_dataset(data_set, labels)\n",
    "    train_test_save_model(train_dataset, validation_data, epochs_to_train)\n",
    "\n",
    "data_set = load_data_set()\n",
    "complete_training_workflow(data_set, epochs_to_train=10, epochs_to_fine_tune=5,layers_to_unfreeze=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fb1a4a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T06:11:05.389247Z",
     "iopub.status.busy": "2024-08-13T06:11:05.388835Z",
     "iopub.status.idle": "2024-08-13T06:11:20.438687Z",
     "shell.execute_reply": "2024-08-13T06:11:20.437528Z"
    },
    "papermill": {
     "duration": 15.096715,
     "end_time": "2024-08-13T06:11:20.441165",
     "exception": false,
     "start_time": "2024-08-13T06:11:05.344450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting...\n",
      "1th iteration out of 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "creating submission...\n",
      "submission created\n"
     ]
    }
   ],
   "source": [
    "# !! load function accesses from the output, not the input. Submitting doesn't have access to output\n",
    "def complete_testing_workflow():\n",
    "    model_path = '/kaggle/input/eff_v2b0_frozen_10_epochs/keras/default/2/eff_v2b0_frozen_layer_10_epochs.h5'\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    print(\"predicting...\")\n",
    "    predictions = predict(model)\n",
    "    \n",
    "    print(\"creating submission...\")\n",
    "    create_submission(predictions)\n",
    "    print(\"submission created\")\n",
    "\n",
    "complete_testing_workflow()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    },
    {
     "datasetId": 5517720,
     "sourceId": 9138256,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 101447,
     "modelInstanceId": 76796,
     "sourceId": 92043,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1360.827197,
   "end_time": "2024-08-13T06:11:23.256266",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-13T05:48:42.429069",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
